{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93581f3-9096-4c02-804a-78b5db1a83f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41798d8b-0218-4454-a177-4957ee309129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.9.8)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.1.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers[deepspeed] in /usr/local/lib/python3.9/dist-packages (4.20.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (1.23.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (3.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (21.3)\n",
      "Requirement already satisfied: deepspeed>=0.6.5 in /usr/local/lib/python3.9/dist-packages (from transformers[deepspeed]) (0.7.2)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (8.0.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (1.10.2.3)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (1.9.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (1.12.0+cu116)\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (3.1.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from deepspeed>=0.6.5->transformers[deepspeed]) (5.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[deepspeed]) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers[deepspeed]) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[deepspeed]) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[deepspeed]) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[deepspeed]) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers[deepspeed]) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "!pip install transformers[deepspeed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb843ce-65b7-4fd3-9c56-0726ce7323bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from transformers import EvalPrediction, TrainerCallback\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc\n",
    "import transformers\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8408b11-9e79-4933-be6a-74a5f4f9825b",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero3.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": true\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": \"auto\",\n",
    "        \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "        \"stage3_param_persistence_threshold\": \"auto\",\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_gather_16bit_weights_on_model_save\": true\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98a581b-f2a5-4801-ae93-257d6a39ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimveit\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa9794-7cb4-4224-925a-7dee8d912148",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac3aac7d-1ee5-4ca7-b698-3c649f4dd7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=FP3\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=FP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4009031-7095-42bf-b9fd-6029978a50bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DeepSpeed requires a distributed environment even when only one process is used.\n",
    "# This emulates a launcher in the notebook\n",
    "#os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "#os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n",
    "#os.environ[\"RANK\"] = \"0\"\n",
    "#os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "#os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9d44e-3fb9-40e3-9fa8-8b30f6b489bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64325ad0-13af-4199-97ea-c468017308e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d049d8-b212-40db-87a8-30a27d7ded16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_PATH = os.path.join(BASE_PATH, 'data/train/cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd5ac81-1c02-4ac5-8847-f9bcb9b6abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 28\n",
    "seed_everything(seed=SEED)\n",
    "MAX_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578e77df-e81c-448d-a28b-0e3ef03d4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2233f68-2fa4-4e3b-a3e1-e2bff9702dcd",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf77d7d6-6a9b-426c-b014-d139f180bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric\n",
    "def mcrmse(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score\n",
    "\n",
    "    \n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    y_pred = torch.Tensor(predictions)\n",
    "    y_true = labels\n",
    "    mcrmse_acc = mcrmse(y_trues=y_true, y_preds=y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'mcrmse': mcrmse_acc}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214efd60-69a7-4b8d-a8cd-8d6c81b5fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.SmoothL1Loss(reduction='mean')\n",
    "        loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873cb061-b596-4263-b80c-07653bd8e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_dir, out_dir, df_train, df_val, \n",
    "                hyperparams={'bs': 4, 'lr': 9e-6, 'ep': 1, 'hidden_dropout_prob': 0.0, 'attention_probs_dropout_prob': 0.0}, \n",
    "                save_model = False):\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    # CREATE DATASETS\n",
    "    dataset_train = Dataset.from_pandas(df_train)\n",
    "    dataset_test = Dataset.from_pandas(df_val)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    \n",
    "    # training scores\n",
    "    scores = []\n",
    "    \n",
    "    def preprocess_data(examples):\n",
    "        # take a batch of texts\n",
    "        text = examples[\"full_text\"]\n",
    "        # encode them\n",
    "        encoding = tokenizer(text, truncation=True, padding=True, max_length=MAX_LENGTH)\n",
    "        # add labels\n",
    "        labels_batch = {k: examples[k] for k in examples.keys() if k in LABELS}\n",
    "        # create numpy array of shape (batch_size, num_labels)\n",
    "        labels_matrix = np.zeros((len(text), len(LABELS)))\n",
    "        # fill numpy array\n",
    "        for idx, label in enumerate(LABELS):\n",
    "            labels_matrix[:, idx] = labels_batch[label]\n",
    "        encoding[\"labels\"] = labels_matrix.tolist()\n",
    "        return encoding\n",
    "\n",
    "    dataset_train_encoded = dataset_train.map(preprocess_data, batched=True, remove_columns=LABELS+[\"full_text\",\"text_id\"])\n",
    "    dataset_test_encoded = dataset_test.map(preprocess_data, batched=True, remove_columns=LABELS+[\"full_text\",\"text_id\"])\n",
    "    \n",
    "    \n",
    "    # MODEL\n",
    "    config = AutoConfig.from_pretrained(model_dir, \n",
    "                                        num_labels=len(LABELS),\n",
    "                                        id2label=id2label,\n",
    "                                        label2id=label2id, \n",
    "                                        hidden_dropout_prob=hyperparams['hidden_dropout_prob'],\n",
    "                                        attention_probs_dropout_prob = hyperparams['attention_probs_dropout_prob']\n",
    "                                        )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir, \n",
    "                                                               config = config)\n",
    "    \n",
    "    # ARGUMENTS\n",
    "    args = TrainingArguments(\n",
    "            output_dir=out_dir,\n",
    "            evaluation_strategy = \"steps\",\n",
    "            warmup_ratio = 0.1,\n",
    "            learning_rate = hyperparams['lr'],\n",
    "            eval_steps = 100, \n",
    "            num_train_epochs=hyperparams['ep'],\n",
    "            lr_scheduler_type='cosine',\n",
    "            load_best_model_at_end=True,\n",
    "            per_device_train_batch_size=hyperparams['bs'],\n",
    "            per_device_eval_batch_size=hyperparams['bs'],\n",
    "            #save_strategy=\"no\",\n",
    "            save_total_limit = 1,\n",
    "            metric_for_best_model=\"mcrmse\",\n",
    "            greater_is_better = False,\n",
    "            report_to=\"wandb\",  # enable logging to W&B\n",
    "            run_name=out_dir,  # name of the W&B run (optional)\n",
    "            #deepspeed=\"ds_config_zero3.json\" #deepspeed\n",
    "     )\n",
    "    \n",
    "    class SaveLogs(TrainerCallback):\n",
    "        \"\"\"\n",
    "        A bare [`TrainerCallback`] that just prints the logs.\n",
    "        \"\"\"\n",
    "\n",
    "        def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "            _ = logs.pop(\"total_flos\", None)\n",
    "            if state.is_local_process_zero:\n",
    "                try:\n",
    "                    scores.append(logs[\"eval_mcrmse\"])\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # TRAINER\n",
    "    trainer = CustomTrainer(model,\n",
    "                            args,\n",
    "                            train_dataset=dataset_train_encoded,\n",
    "                            eval_dataset=dataset_test_encoded,\n",
    "                            tokenizer=tokenizer,\n",
    "                            compute_metrics=compute_metrics,\n",
    "                            callbacks = [SaveLogs]\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(\"trainer\" + out_dir)\n",
    "    wandb.finish()\n",
    "    if save_model:\n",
    "        pass\n",
    "    else:\n",
    "        del model\n",
    "        gc.collect()\n",
    "        return min(scores)\n",
    "    return all_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3806c6a1-f02b-419f-b78d-20eb03dd7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(\"microsoft/deberta-v3-small\", \"out\", pd.read_csv(\"data/train/cv/train_fold_0.csv\"), pd.read_csv(\"data/train/cv/val_fold_0.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f7b7fd6-fff1-474f-9908-4a5b1fd283d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv_v2(model_dir, out_dir, fold_dir, hyperparams={'bs': 4, 'lr': 9e-6, 'ep': 1},\n",
    "                kfolds=[0, 1, 2, 3, 4, 5], continue_training = True):\n",
    "    scores = []\n",
    "    for fold in kfolds:\n",
    "        train_df = pd.read_csv(fold_dir + '/train_fold_' + str(fold) + '.csv')\n",
    "        val_df = pd.read_csv(fold_dir + '/val_fold_' + str(fold) + '.csv')\n",
    "\n",
    "        model_out_dir = out_dir + '/model_fold_' + str(fold)\n",
    "        if continue_training:\n",
    "            final_model_dir = model_dir + '/model_fold_' + str(fold) + '/best'\n",
    "        else:\n",
    "            final_model_dir = model_dir\n",
    "\n",
    "        best_score = train_model(\n",
    "            model_dir=model_dir,\n",
    "            out_dir=model_out_dir,\n",
    "            df_train=train_df,\n",
    "            df_val=val_df,\n",
    "            save_model=False,\n",
    "            hyperparams=hyperparams,\n",
    "          )\n",
    "        scores.append(best_score)\n",
    "    cv_score = np.mean(scores)\n",
    "    return scores, cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890a545b-94e3-446e-8188-9068cdb8e54f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Parameter 'function'=<function train_model.<locals>.preprocess_data at 0x7ffa5b9bac10> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48c88fe7298456499159b941e8a5f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0ba2b0681c4d4d95474064dbeab72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3259\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_081845-1401xf5o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/1401xf5o\" target=\"_blank\">DEBERTA-LARGE/model_fold_0</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1370846927165985, 'eval_mcrmse': 0.5267567038536072, 'eval_runtime': 21.8138, 'eval_samples_per_second': 29.889, 'eval_steps_per_second': 7.472, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14703688025474548, 'eval_mcrmse': 0.5461340546607971, 'eval_runtime': 23.1959, 'eval_samples_per_second': 28.108, 'eval_steps_per_second': 7.027, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11995860934257507, 'eval_mcrmse': 0.4900945723056793, 'eval_runtime': 22.0053, 'eval_samples_per_second': 29.629, 'eval_steps_per_second': 7.407, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12254511564970016, 'eval_mcrmse': 0.4968127906322479, 'eval_runtime': 22.1519, 'eval_samples_per_second': 29.433, 'eval_steps_per_second': 7.358, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4481, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_0/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_0/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12896405160427094, 'eval_mcrmse': 0.5089833736419678, 'eval_runtime': 21.8275, 'eval_samples_per_second': 29.871, 'eval_steps_per_second': 7.468, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_0/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_0/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_0/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10960336774587631, 'eval_mcrmse': 0.4688187837600708, 'eval_runtime': 22.0111, 'eval_samples_per_second': 29.621, 'eval_steps_per_second': 7.405, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13614210486412048, 'eval_mcrmse': 0.5225774049758911, 'eval_runtime': 21.9451, 'eval_samples_per_second': 29.711, 'eval_steps_per_second': 7.428, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11864342540502548, 'eval_mcrmse': 0.4886339008808136, 'eval_runtime': 21.8583, 'eval_samples_per_second': 29.829, 'eval_steps_per_second': 7.457, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10803566873073578, 'eval_mcrmse': 0.46565768122673035, 'eval_runtime': 23.6404, 'eval_samples_per_second': 27.58, 'eval_steps_per_second': 6.895, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1172, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_0/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_0/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10916637629270554, 'eval_mcrmse': 0.4678000509738922, 'eval_runtime': 22.2053, 'eval_samples_per_second': 29.362, 'eval_steps_per_second': 7.341, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_0/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_0/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_0/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_0/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10675899684429169, 'eval_mcrmse': 0.46168509125709534, 'eval_runtime': 21.7841, 'eval_samples_per_second': 29.93, 'eval_steps_per_second': 7.483, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10358770936727524, 'eval_mcrmse': 0.4556765854358673, 'eval_runtime': 21.8822, 'eval_samples_per_second': 29.796, 'eval_steps_per_second': 7.449, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12939292192459106, 'eval_mcrmse': 0.5099655985832214, 'eval_runtime': 21.7825, 'eval_samples_per_second': 29.932, 'eval_steps_per_second': 7.483, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10609663277864456, 'eval_mcrmse': 0.4620300829410553, 'eval_runtime': 22.788, 'eval_samples_per_second': 28.612, 'eval_steps_per_second': 7.153, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0943, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_0/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_0/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10232391953468323, 'eval_mcrmse': 0.45301952958106995, 'eval_runtime': 21.8415, 'eval_samples_per_second': 29.851, 'eval_steps_per_second': 7.463, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_0/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_0/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_0/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_0/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1070546805858612, 'eval_mcrmse': 0.463383287191391, 'eval_runtime': 22.0389, 'eval_samples_per_second': 29.584, 'eval_steps_per_second': 7.396, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10183504968881607, 'eval_mcrmse': 0.45204198360443115, 'eval_runtime': 21.9126, 'eval_samples_per_second': 29.755, 'eval_steps_per_second': 7.439, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1037071943283081, 'eval_mcrmse': 0.4558808505535126, 'eval_runtime': 22.0668, 'eval_samples_per_second': 29.547, 'eval_steps_per_second': 7.387, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10273992270231247, 'eval_mcrmse': 0.4542276859283447, 'eval_runtime': 23.0441, 'eval_samples_per_second': 28.294, 'eval_steps_per_second': 7.073, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10203609615564346, 'eval_mcrmse': 0.45249471068382263, 'eval_runtime': 21.9167, 'eval_samples_per_second': 29.749, 'eval_steps_per_second': 7.437, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10130654275417328, 'eval_mcrmse': 0.4507924020290375, 'eval_runtime': 21.8828, 'eval_samples_per_second': 29.795, 'eval_steps_per_second': 7.449, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1013089194893837, 'eval_mcrmse': 0.4509223699569702, 'eval_runtime': 21.8862, 'eval_samples_per_second': 29.791, 'eval_steps_per_second': 7.448, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1012047529220581, 'eval_mcrmse': 0.45068123936653137, 'eval_runtime': 21.9046, 'eval_samples_per_second': 29.765, 'eval_steps_per_second': 7.441, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_0/checkpoint-2000 (score: 0.4529070556163788).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_0\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_0/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1750.6883, 'train_samples_per_second': 5.585, 'train_steps_per_second': 1.397, 'train_loss': 0.1579831963911622, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_0/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_0/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_0/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed8128477d544ce9d551d7e802a5b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▆█▄▄▅▂▆▄▂▂▂▁▅▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>▇█▄▄▅▂▆▄▂▂▂▁▅▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▆▂▂▁▂▂▁█▃▁▁▁▅▁▂▁▂▆▃▂▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>█▃▇▇█▇▇█▁▆███▄█▇▇▇▃▆▇███</td></tr><tr><td>eval/steps_per_second</td><td>█▃▇▇█▇▇█▁▆███▄█▇▇▇▃▆▇███</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.1012</td></tr><tr><td>eval/mcrmse</td><td>0.45068</td></tr><tr><td>eval/runtime</td><td>21.9046</td></tr><tr><td>eval/samples_per_second</td><td>29.765</td></tr><tr><td>eval/steps_per_second</td><td>7.441</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0641</td></tr><tr><td>train/total_flos</td><td>4555838797046784.0</td></tr><tr><td>train/train_loss</td><td>0.15798</td></tr><tr><td>train/train_runtime</td><td>1750.6883</td></tr><tr><td>train/train_samples_per_second</td><td>5.585</td></tr><tr><td>train/train_steps_per_second</td><td>1.397</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_0</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/1401xf5o\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/1401xf5o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_081845-1401xf5o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55384f8a200e47409966139e9e9dc768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e9af37c0d046a197f5471db4a6e305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3259\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_084816-3t1bmr10</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/3t1bmr10\" target=\"_blank\">DEBERTA-LARGE/model_fold_1</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21462015807628632, 'eval_mcrmse': 0.6707934737205505, 'eval_runtime': 21.861, 'eval_samples_per_second': 29.825, 'eval_steps_per_second': 7.456, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2151668220758438, 'eval_mcrmse': 0.6648253798484802, 'eval_runtime': 21.9917, 'eval_samples_per_second': 29.648, 'eval_steps_per_second': 7.412, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13617165386676788, 'eval_mcrmse': 0.5233010649681091, 'eval_runtime': 21.8459, 'eval_samples_per_second': 29.845, 'eval_steps_per_second': 7.461, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2130146324634552, 'eval_mcrmse': 0.6634412407875061, 'eval_runtime': 21.8702, 'eval_samples_per_second': 29.812, 'eval_steps_per_second': 7.453, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4459, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_1/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_1/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.129531130194664, 'eval_mcrmse': 0.5111370086669922, 'eval_runtime': 22.2245, 'eval_samples_per_second': 29.337, 'eval_steps_per_second': 7.334, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_1/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_1/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_1/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13192009925842285, 'eval_mcrmse': 0.5146897435188293, 'eval_runtime': 21.7785, 'eval_samples_per_second': 29.938, 'eval_steps_per_second': 7.484, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12027673423290253, 'eval_mcrmse': 0.49194014072418213, 'eval_runtime': 23.055, 'eval_samples_per_second': 28.28, 'eval_steps_per_second': 7.07, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11686734855175018, 'eval_mcrmse': 0.4846620559692383, 'eval_runtime': 21.9723, 'eval_samples_per_second': 29.674, 'eval_steps_per_second': 7.418, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12264508008956909, 'eval_mcrmse': 0.4972743093967438, 'eval_runtime': 25.063, 'eval_samples_per_second': 26.014, 'eval_steps_per_second': 6.504, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1208, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_1/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_1/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12253057956695557, 'eval_mcrmse': 0.49697670340538025, 'eval_runtime': 21.8436, 'eval_samples_per_second': 29.849, 'eval_steps_per_second': 7.462, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_1/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_1/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_1/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_1/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13875974714756012, 'eval_mcrmse': 0.5301674008369446, 'eval_runtime': 21.8552, 'eval_samples_per_second': 29.833, 'eval_steps_per_second': 7.458, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11768734455108643, 'eval_mcrmse': 0.48629891872406006, 'eval_runtime': 21.8735, 'eval_samples_per_second': 29.808, 'eval_steps_per_second': 7.452, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11329328268766403, 'eval_mcrmse': 0.47708141803741455, 'eval_runtime': 21.8378, 'eval_samples_per_second': 29.856, 'eval_steps_per_second': 7.464, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11218245327472687, 'eval_mcrmse': 0.47440361976623535, 'eval_runtime': 22.8716, 'eval_samples_per_second': 28.507, 'eval_steps_per_second': 7.127, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0932, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_1/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_1/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10979566723108292, 'eval_mcrmse': 0.4691852629184723, 'eval_runtime': 21.9042, 'eval_samples_per_second': 29.766, 'eval_steps_per_second': 7.441, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_1/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_1/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_1/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_1/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11076731979846954, 'eval_mcrmse': 0.4711887538433075, 'eval_runtime': 21.8234, 'eval_samples_per_second': 29.876, 'eval_steps_per_second': 7.469, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10822010785341263, 'eval_mcrmse': 0.46566176414489746, 'eval_runtime': 21.8774, 'eval_samples_per_second': 29.802, 'eval_steps_per_second': 7.451, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10994858294725418, 'eval_mcrmse': 0.46925392746925354, 'eval_runtime': 21.7836, 'eval_samples_per_second': 29.931, 'eval_steps_per_second': 7.483, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10840417444705963, 'eval_mcrmse': 0.4661999046802521, 'eval_runtime': 21.8212, 'eval_samples_per_second': 29.879, 'eval_steps_per_second': 7.47, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0695, 'learning_rate': 1.9520036835178667e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_1/checkpoint-2000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_1/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10807471722364426, 'eval_mcrmse': 0.46537473797798157, 'eval_runtime': 21.8787, 'eval_samples_per_second': 29.801, 'eval_steps_per_second': 7.45, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_1/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_1/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_1/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_1/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10811436921358109, 'eval_mcrmse': 0.4654439389705658, 'eval_runtime': 21.857, 'eval_samples_per_second': 29.83, 'eval_steps_per_second': 7.458, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10737935453653336, 'eval_mcrmse': 0.4638478457927704, 'eval_runtime': 22.0295, 'eval_samples_per_second': 29.597, 'eval_steps_per_second': 7.399, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10740187764167786, 'eval_mcrmse': 0.46390894055366516, 'eval_runtime': 21.9859, 'eval_samples_per_second': 29.655, 'eval_steps_per_second': 7.414, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10741549730300903, 'eval_mcrmse': 0.4639393389225006, 'eval_runtime': 21.7659, 'eval_samples_per_second': 29.955, 'eval_steps_per_second': 7.489, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_1/checkpoint-2000 (score: 0.46537473797798157).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_1\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_1/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1773.6774, 'train_samples_per_second': 5.512, 'train_steps_per_second': 1.378, 'train_loss': 0.15984971918211394, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_1/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_1/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_1/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▃█▂▃▂▂▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>██▃█▃▃▂▂▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▂▁▄▁█▁▁▁▁▃▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>eval/samples_per_second</td><td>█▇██▇█▅█▁████▅███████▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>█▇██▇█▅▇▁████▅███████▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.10742</td></tr><tr><td>eval/mcrmse</td><td>0.46394</td></tr><tr><td>eval/runtime</td><td>21.7659</td></tr><tr><td>eval/samples_per_second</td><td>29.955</td></tr><tr><td>eval/steps_per_second</td><td>7.489</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0695</td></tr><tr><td>train/total_flos</td><td>4555838797046784.0</td></tr><tr><td>train/train_loss</td><td>0.15985</td></tr><tr><td>train/train_runtime</td><td>1773.6774</td></tr><tr><td>train/train_samples_per_second</td><td>5.512</td></tr><tr><td>train/train_steps_per_second</td><td>1.378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_1</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/3t1bmr10\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/3t1bmr10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_084816-3t1bmr10/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7fe46a86614ac0aa9afc4e8e9b5f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f522822a2e4b1a8e444047bf37cec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3259\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_091807-2xnk3naw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/2xnk3naw\" target=\"_blank\">DEBERTA-LARGE/model_fold_2</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19463416934013367, 'eval_mcrmse': 0.6292238235473633, 'eval_runtime': 21.808, 'eval_samples_per_second': 29.897, 'eval_steps_per_second': 7.474, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1630294919013977, 'eval_mcrmse': 0.5752027630805969, 'eval_runtime': 21.8223, 'eval_samples_per_second': 29.878, 'eval_steps_per_second': 7.469, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16391751170158386, 'eval_mcrmse': 0.577516496181488, 'eval_runtime': 21.8591, 'eval_samples_per_second': 29.827, 'eval_steps_per_second': 7.457, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13241831958293915, 'eval_mcrmse': 0.5164709687232971, 'eval_runtime': 21.8633, 'eval_samples_per_second': 29.822, 'eval_steps_per_second': 7.455, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4379, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_2/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_2/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1317400485277176, 'eval_mcrmse': 0.5137775540351868, 'eval_runtime': 21.877, 'eval_samples_per_second': 29.803, 'eval_steps_per_second': 7.451, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_2/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1326916664838791, 'eval_mcrmse': 0.5152541995048523, 'eval_runtime': 21.8238, 'eval_samples_per_second': 29.876, 'eval_steps_per_second': 7.469, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12667304277420044, 'eval_mcrmse': 0.5051281452178955, 'eval_runtime': 22.4087, 'eval_samples_per_second': 29.096, 'eval_steps_per_second': 7.274, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12194082140922546, 'eval_mcrmse': 0.49487996101379395, 'eval_runtime': 21.9822, 'eval_samples_per_second': 29.66, 'eval_steps_per_second': 7.415, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1256069839000702, 'eval_mcrmse': 0.5032078623771667, 'eval_runtime': 21.8176, 'eval_samples_per_second': 29.884, 'eval_steps_per_second': 7.471, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.118, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_2/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_2/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11577456444501877, 'eval_mcrmse': 0.482128381729126, 'eval_runtime': 21.8901, 'eval_samples_per_second': 29.785, 'eval_steps_per_second': 7.446, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_2/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_2/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11685344576835632, 'eval_mcrmse': 0.4841444790363312, 'eval_runtime': 21.8206, 'eval_samples_per_second': 29.88, 'eval_steps_per_second': 7.47, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11725005507469177, 'eval_mcrmse': 0.4859500825405121, 'eval_runtime': 21.9493, 'eval_samples_per_second': 29.705, 'eval_steps_per_second': 7.426, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11332755535840988, 'eval_mcrmse': 0.4770815074443817, 'eval_runtime': 21.8937, 'eval_samples_per_second': 29.78, 'eval_steps_per_second': 7.445, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1378432959318161, 'eval_mcrmse': 0.5267776250839233, 'eval_runtime': 23.0283, 'eval_samples_per_second': 28.313, 'eval_steps_per_second': 7.078, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0955, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_2/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_2/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1147896945476532, 'eval_mcrmse': 0.4803767204284668, 'eval_runtime': 21.9931, 'eval_samples_per_second': 29.646, 'eval_steps_per_second': 7.411, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_2/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_2/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11031550168991089, 'eval_mcrmse': 0.470780611038208, 'eval_runtime': 22.0603, 'eval_samples_per_second': 29.555, 'eval_steps_per_second': 7.389, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10971738398075104, 'eval_mcrmse': 0.4694833755493164, 'eval_runtime': 21.9281, 'eval_samples_per_second': 29.734, 'eval_steps_per_second': 7.433, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11548476666212082, 'eval_mcrmse': 0.48154914379119873, 'eval_runtime': 21.8568, 'eval_samples_per_second': 29.831, 'eval_steps_per_second': 7.458, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11203035712242126, 'eval_mcrmse': 0.4742553234100342, 'eval_runtime': 21.9631, 'eval_samples_per_second': 29.686, 'eval_steps_per_second': 7.422, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0676, 'learning_rate': 1.9520036835178667e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_2/checkpoint-2000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_2/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11256564408540726, 'eval_mcrmse': 0.475892037153244, 'eval_runtime': 21.8408, 'eval_samples_per_second': 29.852, 'eval_steps_per_second': 7.463, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_2/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_2/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10964980721473694, 'eval_mcrmse': 0.46915867924690247, 'eval_runtime': 21.822, 'eval_samples_per_second': 29.878, 'eval_steps_per_second': 7.47, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10997775942087173, 'eval_mcrmse': 0.4699234664440155, 'eval_runtime': 22.0726, 'eval_samples_per_second': 29.539, 'eval_steps_per_second': 7.385, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11005282402038574, 'eval_mcrmse': 0.4701957404613495, 'eval_runtime': 21.9796, 'eval_samples_per_second': 29.664, 'eval_steps_per_second': 7.416, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11001697927713394, 'eval_mcrmse': 0.47012266516685486, 'eval_runtime': 22.8385, 'eval_samples_per_second': 28.548, 'eval_steps_per_second': 7.137, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_2/checkpoint-2000 (score: 0.475892037153244).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_2\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_2/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1764.0384, 'train_samples_per_second': 5.542, 'train_steps_per_second': 1.386, 'train_loss': 0.15742389702358128, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_2/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_2/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_2/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▅▃▃▃▂▂▂▂▂▂▁▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>█▆▆▃▃▃▃▂▂▂▂▂▁▄▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▄▂▁▁▁▂▁█▂▂▂▁▂▁▁▃▂▇</td></tr><tr><td>eval/samples_per_second</td><td>██████▄▇███▇▇▁▇▆▇█▇██▆▇▂</td></tr><tr><td>eval/steps_per_second</td><td>██████▄▇███▇▇▁▇▆▇█▇██▆▇▂</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.11002</td></tr><tr><td>eval/mcrmse</td><td>0.47012</td></tr><tr><td>eval/runtime</td><td>22.8385</td></tr><tr><td>eval/samples_per_second</td><td>28.548</td></tr><tr><td>eval/steps_per_second</td><td>7.137</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0676</td></tr><tr><td>train/total_flos</td><td>4555838797046784.0</td></tr><tr><td>train/train_loss</td><td>0.15742</td></tr><tr><td>train/train_runtime</td><td>1764.0384</td></tr><tr><td>train/train_samples_per_second</td><td>5.542</td></tr><tr><td>train/train_steps_per_second</td><td>1.386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_2</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/2xnk3naw\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/2xnk3naw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_091807-2xnk3naw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c01cccc26f47d3841e56dd49544754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d417dec0f6d477ba9bc2427d56d62b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3259\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_094746-y1kl6iv0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/y1kl6iv0\" target=\"_blank\">DEBERTA-LARGE/model_fold_3</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17355100810527802, 'eval_mcrmse': 0.597622811794281, 'eval_runtime': 21.9913, 'eval_samples_per_second': 29.648, 'eval_steps_per_second': 7.412, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2946293354034424, 'eval_mcrmse': 0.8326303362846375, 'eval_runtime': 22.3308, 'eval_samples_per_second': 29.197, 'eval_steps_per_second': 7.299, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1289903223514557, 'eval_mcrmse': 0.5078224539756775, 'eval_runtime': 23.4144, 'eval_samples_per_second': 27.846, 'eval_steps_per_second': 6.962, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1190231442451477, 'eval_mcrmse': 0.4892277717590332, 'eval_runtime': 21.8716, 'eval_samples_per_second': 29.81, 'eval_steps_per_second': 7.453, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4584, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_3/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_3/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1450168937444687, 'eval_mcrmse': 0.5403605699539185, 'eval_runtime': 21.8165, 'eval_samples_per_second': 29.886, 'eval_steps_per_second': 7.471, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_3/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_3/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_3/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11942071467638016, 'eval_mcrmse': 0.48967185616493225, 'eval_runtime': 21.7773, 'eval_samples_per_second': 29.939, 'eval_steps_per_second': 7.485, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1294674426317215, 'eval_mcrmse': 0.512749969959259, 'eval_runtime': 21.9454, 'eval_samples_per_second': 29.71, 'eval_steps_per_second': 7.428, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11501263082027435, 'eval_mcrmse': 0.48060718178749084, 'eval_runtime': 22.7231, 'eval_samples_per_second': 28.693, 'eval_steps_per_second': 7.173, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1225045770406723, 'eval_mcrmse': 0.49544429779052734, 'eval_runtime': 21.8827, 'eval_samples_per_second': 29.795, 'eval_steps_per_second': 7.449, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1194, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_3/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_3/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11953000724315643, 'eval_mcrmse': 0.4909560978412628, 'eval_runtime': 23.1709, 'eval_samples_per_second': 28.139, 'eval_steps_per_second': 7.035, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_3/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_3/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_3/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_3/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10827372223138809, 'eval_mcrmse': 0.4662870466709137, 'eval_runtime': 21.8945, 'eval_samples_per_second': 29.779, 'eval_steps_per_second': 7.445, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10547565668821335, 'eval_mcrmse': 0.46012595295906067, 'eval_runtime': 21.8269, 'eval_samples_per_second': 29.871, 'eval_steps_per_second': 7.468, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11970259994268417, 'eval_mcrmse': 0.4909043312072754, 'eval_runtime': 22.1249, 'eval_samples_per_second': 29.469, 'eval_steps_per_second': 7.367, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10829336941242218, 'eval_mcrmse': 0.46654054522514343, 'eval_runtime': 21.7866, 'eval_samples_per_second': 29.927, 'eval_steps_per_second': 7.482, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0945, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_3/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_3/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10898231714963913, 'eval_mcrmse': 0.46781793236732483, 'eval_runtime': 23.1378, 'eval_samples_per_second': 28.179, 'eval_steps_per_second': 7.045, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_3/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_3/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_3/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_3/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10875146090984344, 'eval_mcrmse': 0.4671614468097687, 'eval_runtime': 21.7897, 'eval_samples_per_second': 29.922, 'eval_steps_per_second': 7.481, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10704611241817474, 'eval_mcrmse': 0.4636197090148926, 'eval_runtime': 22.2855, 'eval_samples_per_second': 29.257, 'eval_steps_per_second': 7.314, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10733963549137115, 'eval_mcrmse': 0.4642641246318817, 'eval_runtime': 21.9482, 'eval_samples_per_second': 29.706, 'eval_steps_per_second': 7.427, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10864907503128052, 'eval_mcrmse': 0.46713629364967346, 'eval_runtime': 22.0941, 'eval_samples_per_second': 29.51, 'eval_steps_per_second': 7.378, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0677, 'learning_rate': 1.9520036835178667e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_3/checkpoint-2000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_3/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10612836480140686, 'eval_mcrmse': 0.4614690840244293, 'eval_runtime': 22.0047, 'eval_samples_per_second': 29.63, 'eval_steps_per_second': 7.408, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_3/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_3/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_3/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_3/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10540474206209183, 'eval_mcrmse': 0.4597926437854767, 'eval_runtime': 21.9947, 'eval_samples_per_second': 29.644, 'eval_steps_per_second': 7.411, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10536673665046692, 'eval_mcrmse': 0.4597257673740387, 'eval_runtime': 22.0216, 'eval_samples_per_second': 29.607, 'eval_steps_per_second': 7.402, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10538946092128754, 'eval_mcrmse': 0.45976564288139343, 'eval_runtime': 21.8146, 'eval_samples_per_second': 29.888, 'eval_steps_per_second': 7.472, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10536704212427139, 'eval_mcrmse': 0.4597109258174896, 'eval_runtime': 21.8493, 'eval_samples_per_second': 29.841, 'eval_steps_per_second': 7.46, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_3/checkpoint-2000 (score: 0.4614690840244293).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_3\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_3/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1767.1689, 'train_samples_per_second': 5.533, 'train_steps_per_second': 1.384, 'train_loss': 0.16159235090322047, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_3/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_3/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_3/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▄█▂▂▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>▄█▂▂▃▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▃█▁▁▁▂▅▁▇▂▁▂▁▇▁▃▂▂▂▂▂▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▆▁███▇▄█▂▇█▆█▂█▆▇▇▇▇▇██</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▁███▇▄█▂▇█▆█▂█▆▇▇▇▇▇██</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.10537</td></tr><tr><td>eval/mcrmse</td><td>0.45971</td></tr><tr><td>eval/runtime</td><td>21.8493</td></tr><tr><td>eval/samples_per_second</td><td>29.841</td></tr><tr><td>eval/steps_per_second</td><td>7.46</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0677</td></tr><tr><td>train/total_flos</td><td>4555838797046784.0</td></tr><tr><td>train/train_loss</td><td>0.16159</td></tr><tr><td>train/train_runtime</td><td>1767.1689</td></tr><tr><td>train/train_samples_per_second</td><td>5.533</td></tr><tr><td>train/train_steps_per_second</td><td>1.384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_3</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/y1kl6iv0\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/y1kl6iv0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_094746-y1kl6iv0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2707b4fb3d4287b28a6479889836b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b9a312b35d46bcb441575fd014f92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3260\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_101727-mgx9hl94</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/mgx9hl94\" target=\"_blank\">DEBERTA-LARGE/model_fold_4</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25637558102607727, 'eval_mcrmse': 0.738994836807251, 'eval_runtime': 21.8454, 'eval_samples_per_second': 29.8, 'eval_steps_per_second': 7.462, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20440465211868286, 'eval_mcrmse': 0.6469113230705261, 'eval_runtime': 21.9173, 'eval_samples_per_second': 29.703, 'eval_steps_per_second': 7.437, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15186165273189545, 'eval_mcrmse': 0.5524607300758362, 'eval_runtime': 21.7831, 'eval_samples_per_second': 29.886, 'eval_steps_per_second': 7.483, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14916324615478516, 'eval_mcrmse': 0.5509610772132874, 'eval_runtime': 21.7787, 'eval_samples_per_second': 29.892, 'eval_steps_per_second': 7.484, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4482, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_4/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_4/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11898963898420334, 'eval_mcrmse': 0.48939600586891174, 'eval_runtime': 27.7081, 'eval_samples_per_second': 23.495, 'eval_steps_per_second': 5.883, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_4/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_4/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_4/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13274994492530823, 'eval_mcrmse': 0.517382800579071, 'eval_runtime': 21.7231, 'eval_samples_per_second': 29.968, 'eval_steps_per_second': 7.504, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12069390714168549, 'eval_mcrmse': 0.4929755926132202, 'eval_runtime': 21.8748, 'eval_samples_per_second': 29.76, 'eval_steps_per_second': 7.452, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12626004219055176, 'eval_mcrmse': 0.5051617622375488, 'eval_runtime': 21.8583, 'eval_samples_per_second': 29.783, 'eval_steps_per_second': 7.457, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1075499951839447, 'eval_mcrmse': 0.4651283323764801, 'eval_runtime': 21.8291, 'eval_samples_per_second': 29.823, 'eval_steps_per_second': 7.467, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1206, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_4/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_4/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11658301949501038, 'eval_mcrmse': 0.4840054214000702, 'eval_runtime': 24.124, 'eval_samples_per_second': 26.986, 'eval_steps_per_second': 6.757, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_4/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_4/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_4/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_4/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1200837641954422, 'eval_mcrmse': 0.4916214644908905, 'eval_runtime': 21.7576, 'eval_samples_per_second': 29.921, 'eval_steps_per_second': 7.492, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11270428448915482, 'eval_mcrmse': 0.476224422454834, 'eval_runtime': 21.8446, 'eval_samples_per_second': 29.801, 'eval_steps_per_second': 7.462, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10679031163454056, 'eval_mcrmse': 0.4631342887878418, 'eval_runtime': 21.9741, 'eval_samples_per_second': 29.626, 'eval_steps_per_second': 7.418, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10796169936656952, 'eval_mcrmse': 0.466154545545578, 'eval_runtime': 21.8153, 'eval_samples_per_second': 29.841, 'eval_steps_per_second': 7.472, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0952, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_4/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_4/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11097747832536697, 'eval_mcrmse': 0.4722318947315216, 'eval_runtime': 21.7868, 'eval_samples_per_second': 29.88, 'eval_steps_per_second': 7.482, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_4/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_4/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_4/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_4/checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10865263640880585, 'eval_mcrmse': 0.4668833315372467, 'eval_runtime': 22.0988, 'eval_samples_per_second': 29.459, 'eval_steps_per_second': 7.376, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10557871311903, 'eval_mcrmse': 0.4604159891605377, 'eval_runtime': 23.1789, 'eval_samples_per_second': 28.086, 'eval_steps_per_second': 7.032, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10486762225627899, 'eval_mcrmse': 0.45880410075187683, 'eval_runtime': 22.0924, 'eval_samples_per_second': 29.467, 'eval_steps_per_second': 7.378, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10549431294202805, 'eval_mcrmse': 0.46033430099487305, 'eval_runtime': 22.0213, 'eval_samples_per_second': 29.562, 'eval_steps_per_second': 7.402, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0676, 'learning_rate': 1.9520036835178667e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_4/checkpoint-2000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_4/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10484741628170013, 'eval_mcrmse': 0.4589599072933197, 'eval_runtime': 21.8538, 'eval_samples_per_second': 29.789, 'eval_steps_per_second': 7.459, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_4/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_4/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_4/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_4/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10455658286809921, 'eval_mcrmse': 0.45833835005760193, 'eval_runtime': 21.9481, 'eval_samples_per_second': 29.661, 'eval_steps_per_second': 7.427, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10460924357175827, 'eval_mcrmse': 0.458395391702652, 'eval_runtime': 22.9211, 'eval_samples_per_second': 28.402, 'eval_steps_per_second': 7.111, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10425802320241928, 'eval_mcrmse': 0.4576106071472168, 'eval_runtime': 22.165, 'eval_samples_per_second': 29.371, 'eval_steps_per_second': 7.354, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 651\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10417678952217102, 'eval_mcrmse': 0.4574316740036011, 'eval_runtime': 21.8389, 'eval_samples_per_second': 29.809, 'eval_steps_per_second': 7.464, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_4/checkpoint-2000 (score: 0.4589599072933197).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_4\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_4/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1775.5151, 'train_samples_per_second': 5.508, 'train_steps_per_second': 1.377, 'train_loss': 0.15999494057247732, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_4/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_4/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_4/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▃▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>█▆▃▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁█▁▁▁▁▄▁▁▁▁▁▁▃▁▁▁▁▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>████▁████▅█████▇▆▇███▆▇█</td></tr><tr><td>eval/steps_per_second</td><td>████▁████▅█████▇▆▇███▆▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.10418</td></tr><tr><td>eval/mcrmse</td><td>0.45743</td></tr><tr><td>eval/runtime</td><td>21.8389</td></tr><tr><td>eval/samples_per_second</td><td>29.809</td></tr><tr><td>eval/steps_per_second</td><td>7.464</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0676</td></tr><tr><td>train/total_flos</td><td>4557236722421760.0</td></tr><tr><td>train/train_loss</td><td>0.15999</td></tr><tr><td>train/train_runtime</td><td>1775.5151</td></tr><tr><td>train/train_samples_per_second</td><td>5.508</td></tr><tr><td>train/train_steps_per_second</td><td>1.377</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_4</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/mgx9hl94\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/mgx9hl94</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_101727-mgx9hl94/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90102d5d4c2e4a5eb2ea6c43440b7d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6622c522700b4192bbf06f840386619a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3259\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2445\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220916_104718-2t2weli5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simveit/FP3/runs/2t2weli5\" target=\"_blank\">DEBERTA-LARGE/model_fold_5</a></strong> to <a href=\"https://wandb.ai/simveit/FP3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1798526495695114, 'eval_mcrmse': 0.6080383658409119, 'eval_runtime': 23.7709, 'eval_samples_per_second': 27.428, 'eval_steps_per_second': 6.857, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2216256707906723, 'eval_mcrmse': 0.6690865159034729, 'eval_runtime': 21.9426, 'eval_samples_per_second': 29.714, 'eval_steps_per_second': 7.428, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13361552357673645, 'eval_mcrmse': 0.5195302367210388, 'eval_runtime': 22.7663, 'eval_samples_per_second': 28.639, 'eval_steps_per_second': 7.16, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12345369160175323, 'eval_mcrmse': 0.49946311116218567, 'eval_runtime': 21.881, 'eval_samples_per_second': 29.798, 'eval_steps_per_second': 7.449, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4473, 'learning_rate': 1.9344306953445632e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_5/checkpoint-500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_5/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15058931708335876, 'eval_mcrmse': 0.5515605807304382, 'eval_runtime': 23.4326, 'eval_samples_per_second': 27.824, 'eval_steps_per_second': 6.956, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_5/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_5/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_5/checkpoint-500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1271062195301056, 'eval_mcrmse': 0.5065149664878845, 'eval_runtime': 21.7863, 'eval_samples_per_second': 29.927, 'eval_steps_per_second': 7.482, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13798366487026215, 'eval_mcrmse': 0.5297662615776062, 'eval_runtime': 21.8769, 'eval_samples_per_second': 29.803, 'eval_steps_per_second': 7.451, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12199853360652924, 'eval_mcrmse': 0.4962909519672394, 'eval_runtime': 21.8253, 'eval_samples_per_second': 29.874, 'eval_steps_per_second': 7.468, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11790776252746582, 'eval_mcrmse': 0.4872227907180786, 'eval_runtime': 23.2406, 'eval_samples_per_second': 28.054, 'eval_steps_per_second': 7.014, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1146, 'learning_rate': 1.4729702107813438e-05, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_5/checkpoint-1000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_5/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11980653554201126, 'eval_mcrmse': 0.4916222095489502, 'eval_runtime': 21.9101, 'eval_samples_per_second': 29.758, 'eval_steps_per_second': 7.439, 'epoch': 1.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_5/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_5/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_5/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_5/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12172272056341171, 'eval_mcrmse': 0.4951744079589844, 'eval_runtime': 21.809, 'eval_samples_per_second': 29.896, 'eval_steps_per_second': 7.474, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11977870762348175, 'eval_mcrmse': 0.4914788007736206, 'eval_runtime': 22.082, 'eval_samples_per_second': 29.526, 'eval_steps_per_second': 7.382, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12291842699050903, 'eval_mcrmse': 0.4982386827468872, 'eval_runtime': 21.8613, 'eval_samples_per_second': 29.824, 'eval_steps_per_second': 7.456, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12130042165517807, 'eval_mcrmse': 0.4948798418045044, 'eval_runtime': 21.9977, 'eval_samples_per_second': 29.64, 'eval_steps_per_second': 7.41, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0951, 'learning_rate': 7.804633756159258e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_5/checkpoint-1500\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_5/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12334058433771133, 'eval_mcrmse': 0.4986139237880707, 'eval_runtime': 22.0426, 'eval_samples_per_second': 29.579, 'eval_steps_per_second': 7.395, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_5/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_5/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_5/checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12401095032691956, 'eval_mcrmse': 0.4999326765537262, 'eval_runtime': 22.8639, 'eval_samples_per_second': 28.517, 'eval_steps_per_second': 7.129, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11435551196336746, 'eval_mcrmse': 0.47974538803100586, 'eval_runtime': 22.2855, 'eval_samples_per_second': 29.257, 'eval_steps_per_second': 7.314, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11712316423654556, 'eval_mcrmse': 0.48600277304649353, 'eval_runtime': 21.9812, 'eval_samples_per_second': 29.662, 'eval_steps_per_second': 7.415, 'epoch': 2.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11336223781108856, 'eval_mcrmse': 0.47774598002433777, 'eval_runtime': 21.8012, 'eval_samples_per_second': 29.907, 'eval_steps_per_second': 7.477, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0671, 'learning_rate': 1.9520036835178667e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to DEBERTA-LARGE/model_fold_5/checkpoint-2000\n",
      "Configuration saved in DEBERTA-LARGE/model_fold_5/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11338387429714203, 'eval_mcrmse': 0.47765398025512695, 'eval_runtime': 22.3298, 'eval_samples_per_second': 29.199, 'eval_steps_per_second': 7.3, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in DEBERTA-LARGE/model_fold_5/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in DEBERTA-LARGE/model_fold_5/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in DEBERTA-LARGE/model_fold_5/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_5/checkpoint-1000] due to args.save_total_limit\n",
      "Deleting older checkpoint [DEBERTA-LARGE/model_fold_5/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11291727423667908, 'eval_mcrmse': 0.4767405092716217, 'eval_runtime': 21.9016, 'eval_samples_per_second': 29.77, 'eval_steps_per_second': 7.442, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11202742159366608, 'eval_mcrmse': 0.4748063385486603, 'eval_runtime': 23.1985, 'eval_samples_per_second': 28.105, 'eval_steps_per_second': 7.026, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11251739412546158, 'eval_mcrmse': 0.475888729095459, 'eval_runtime': 21.8107, 'eval_samples_per_second': 29.894, 'eval_steps_per_second': 7.473, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 652\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11227554827928543, 'eval_mcrmse': 0.4753783047199249, 'eval_runtime': 22.0779, 'eval_samples_per_second': 29.532, 'eval_steps_per_second': 7.383, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from DEBERTA-LARGE/model_fold_5/checkpoint-2000 (score: 0.47765398025512695).\n",
      "Saving model checkpoint to trainerDEBERTA-LARGE/model_fold_5\n",
      "Configuration saved in trainerDEBERTA-LARGE/model_fold_5/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1769.0949, 'train_samples_per_second': 5.527, 'train_steps_per_second': 1.382, 'train_loss': 0.15810979831438124, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in trainerDEBERTA-LARGE/model_fold_5/pytorch_model.bin\n",
      "tokenizer config file saved in trainerDEBERTA-LARGE/model_fold_5/tokenizer_config.json\n",
      "Special tokens file saved in trainerDEBERTA-LARGE/model_fold_5/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▅█▂▂▃▂▃▂▁▁▂▁▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/mcrmse</td><td>▆█▃▂▄▂▃▂▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▂▄▁▇▁▁▁▆▁▁▂▁▂▂▅▃▂▁▃▁▆▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▄█▂███▃██▇█▇▇▄▆▇█▆█▃█▇</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▄█▂███▃██▇█▇▇▄▆▇█▆█▃█▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.11228</td></tr><tr><td>eval/mcrmse</td><td>0.47538</td></tr><tr><td>eval/runtime</td><td>22.0779</td></tr><tr><td>eval/samples_per_second</td><td>29.532</td></tr><tr><td>eval/steps_per_second</td><td>7.383</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>2445</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0671</td></tr><tr><td>train/total_flos</td><td>4555838797046784.0</td></tr><tr><td>train/train_loss</td><td>0.15811</td></tr><tr><td>train/train_runtime</td><td>1769.0949</td></tr><tr><td>train/train_samples_per_second</td><td>5.527</td></tr><tr><td>train/train_steps_per_second</td><td>1.382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DEBERTA-LARGE/model_fold_5</strong>: <a href=\"https://wandb.ai/simveit/FP3/runs/2t2weli5\" target=\"_blank\">https://wandb.ai/simveit/FP3/runs/2t2weli5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220916_104718-2t2weli5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_dir = \"microsoft/deberta-v3-large\"\n",
    "fold_dir = BASE_PATH + \"/data/train/cv\"\n",
    "out_dir = \"DEBERTA-LARGE\"\n",
    "hyperparams = {'bs': 4, 'lr': 2e-5, 'ep': 3, 'hidden_dropout_prob': 0.0, 'attention_probs_dropout_prob': 0.0}\n",
    "scores, cv_score = train_cv_v2(model_dir, out_dir, fold_dir, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef27d068-83e9-4f29-ba94-a2f6a9413aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores =  [0.45068123936653137, 0.4638478457927704, 0.46915867924690247, 0.4597109258174896, 0.4574316740036011, 0.4748063385486603]\n",
      "cv_score =  0.46260611712932587\n"
     ]
    }
   ],
   "source": [
    "print(\"scores = \", scores)\n",
    "print(\"cv_score = \", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991183a-0509-4561-b146-f170462baa15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
